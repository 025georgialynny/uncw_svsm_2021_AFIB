{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea18b50-839c-41b9-89dc-b9bc831f76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import wfdb\n",
    "import copy as cp\n",
    "import scipy.signal as signal\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8fc3db-52ee-45aa-aa1e-2c5c2f0cfced",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = [] # Initialize the array that will hold the list of our records\n",
    "\n",
    "records = 'mit-bih-dataframes/subject_list.csv' # Get our record list like we did in the initial extraction\n",
    "with open(records) as rfile:# Load our records into the array\n",
    "    for record in rfile:\n",
    "        record = record[0:-1] # The -1 removes the newline (\"\\n\") character from the string\n",
    "        record_list.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93830edf-cc3e-4b64-8cc7-12501c1c7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_ints = [] # Initialize the array that will hold all of our subjects' RR-Intervals\n",
    "\n",
    "for idx, subj in enumerate(record_list): # Iterate through our subject ids\n",
    "    rr_ints.append(np.genfromtxt('mit-bih-rr-intervals/'+str(subj)+'.csv',delimiter=',')) # Add to master array\n",
    "       #NOTE = change 'mit-bih-rr-intervals/' to the appropriate location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484c80b5-5df1-412c-8391-e38b0a9f118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:00, 44.48it/s]\n"
     ]
    }
   ],
   "source": [
    "outlier_list=[]\n",
    "rrs=[]\n",
    "for idx, subj in tqdm(enumerate(rr_ints)):\n",
    "    outlier = [[],[]] # I want to store the index and the outlier\n",
    "    for idx2, rr in enumerate(subj):\n",
    "        if rr > 500:\n",
    "            outlier[0].append(rr) # add the rr int to our list\n",
    "            outlier[1].append(idx2) # Add its index to our list\n",
    "    subj = np.delete(subj, outlier[1]) # Remove all found outliers from our subject \n",
    "    rrs.append(subj) # Add it to our new rr interval list\n",
    "    outlier_list.append(outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f1d7c3-c31a-45b6-9e38-d0c3e2077729",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Setup subset dictionary\n",
    "subset_list = {}\n",
    "for x in record_list:\n",
    "    subset_list[x] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2935fd-a903-4f38-acd3-ea27100d292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 18.99it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_len_sec = 25 # Set the time we are going to subset by\n",
    "subset_len_samp = subset_len_sec*250 # Get that timme in samplse\n",
    "\n",
    "for idx, subj in tqdm(enumerate(rrs)):\n",
    "    samp = 0\n",
    "    while samp < len(subj):\n",
    "        subs_len = 0\n",
    "        subs = []\n",
    "        while subs_len < subset_len_samp and samp<len(subj):\n",
    "            rr = subj[samp]\n",
    "            subs.append(rr)\n",
    "            subs_len+=rr\n",
    "            samp+=1\n",
    "        subset_list[record_list[idx]].append(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04528378-e826-4753-b5d2-c03ce1810482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [02:34<00:00,  6.71s/it]\n"
     ]
    }
   ],
   "source": [
    "subset_record_list = []\n",
    "reload_flag=True\n",
    "for idx, x in enumerate(tqdm(record_list)): \n",
    "    subset_record_list = []\n",
    "    for num, subset in enumerate(subset_list[x]):\n",
    "        if not os.path.exists('mit_bih_subset/'+x+ '-'+str(num)+'.csv') or reload_flag:\n",
    "            np.savetxt('mit_bih_subset/'+x+ '-'+str(num)+'.csv', subset, delimiter=\",\",  fmt='%s') \n",
    "            \n",
    "            subset_record_list.append(x+ '-'+str(num)+'.csv')\n",
    "    if not os.path.exists('mit_bih_subset/'+x+ '-'+str(num)+'.csv') or reload_flag:\n",
    "        np.savetxt('mit_bih_subset/'+x+'_subsetlist.csv', subset, delimiter=\",\",  fmt='%s') \n",
    "            # We'll load the complete list of subjects as well so that we can easily recreate the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b9182-e4c2-448c-bff8-c16f479345c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
